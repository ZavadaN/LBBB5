Adam = ADAptive Moment Estimation

Adam - адаптивная оценка момента. Используются две переменные скользящего среднего:

𝑣
 – первый момент 𝑠
 – второй момент Алгоритм вычисляет экспоненциально взвешенное среднее прошлых градиентов и их квадратов градиентов. Эти скользящие средние затем используются для обновления параметров модели.

Алгоритм Адама состоит из следующих шагов:

Инициализация переменных. Алгоритм начинается с инициализации переменных скользящего среднего 𝑣
 и 𝑠
 - словарей для хранения экспоненциально взвешенных средних градиентов и квадратов градиентов соответственно.

Вычисление скользящих средних. Для каждого параметра модели алгоритм вычисляет скользящее среднее градиентов путем объединения текущего градиента с предыдущим скользящим средним. Также вычисляется скользящее среднее квадратов градиентов. Коррекция смещения. Чтобы уменьшить смещение во время начальных итераций, Adam выполняет коррекцию смещения путем деления скользящих средних на поправочный коэффициент. Обновление параметров. Алгоритм обновляет параметры модели, используя скользящие средние градиентов и квадраты градиентов.

𝑠𝑡𝑣𝑡𝑠𝑡^𝑣𝑡^𝑤𝑡+1=𝛽1𝑠𝑡−1+(1–𝛽1)∇𝑤𝑡=𝛽2𝑣𝑡−1+(1–𝛽2)(∇𝑤𝑡)2=𝑠𝑡1–𝛽1𝑡=𝑣𝑡1–𝛽2𝑡=𝑤𝑡–𝛼𝑠𝑡^𝑣𝑡^+𝜖⎯⎯⎯⎯⎯⎯⎯⎯⎯√
𝑤𝑡
 - веса модели;

learning_rate (𝛼
) - скорость обучения;

𝛽1,𝛽2
 - скорости затухания для первого и второго моментов соответственно;

𝑠
 - оценка первого момента (среднее) градиентов;

𝑣
 - оценка второго момента (нецентрированная дисперсия) градиентов;

𝑡
 - текущая итерация;

𝜖
 - маленькое число, чтобы избежать деления на 0.

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
​
# целевая функция
def objective(x1, x2):
    return x1**2 + x2**2
​
# градиент целевой функции
def gradient(x1, x2):
    return np.array([2*x1, 2*x2])
​
# инициализация моментов
def init_adam():
    s = np.zeros(2)
    v = np.zeros(2)
    return s, v
​
# шаг Adam - пересчет параметров
def adam_update_weights(x, grad, s, v, iteration, learning_rate, beta1, beta2, epsylon = 1e-8):
    s = beta1*s + (1 - beta1)*grad
    v = beta2*v + (1 - beta2)*(grad**2)
    s_hat = s / (1 - beta1**(iteration + 1))
    v_hat = v / (1 - beta2**(iteration + 1))
    x -= learning_rate * s_hat / (np.sqrt(v_hat) + epsylon)
    return x, s, v
​
# алгоритм Adam
def adam(objective, grad, bounds, max_iter, learning_rate, beta1, beta2, epsylon = 1e-8):
    # начальная точка
    x = bounds[:, 0] + np.random.rand(len(bounds))*(bounds[:, 1] - bounds[:, 0])
    score = objective(x[0], x[1])
    scores, trajectory = [], []
    # инициализация моментов
    s, v = init_adam()
    
    # градиентный спуск Adam
    for _ in range(max_iter):
        # вычисление градиента
        grad = gradient(x[0], x[1])
        
        # пересчет параметров
        x, s, v = adam_update_weights(x, grad, s, v, _, learning_rate, beta1, beta2, epsylon)
        
        # вычисление целевой функции
        score = objective(x[0], x[1])
        scores.append(score)
        trajectory.append(x.copy())
        
        # print(">%d f(%s) = %.15f" % (_, x, score)) 
    return x, scores, trajectory
​
np.random.seed(12345678)
​
# определение границ
bounds = np.array([[-1.0, 1.0], [-1.0, 1.0]])
​
max_iter = 160
learning_rate = 0.01
beta1 = 0.8
beta2 = 0.999
​
# Градиентный спуск Adam
x_min, scores, trajectory = adam(objective, gradient, bounds, max_iter, learning_rate, beta1, beta2)
print("Минимум найден:")
print("f(%s) = %f" % (x_min, scores[-1]))
​
# визуализация
x = np.linspace(bounds[0, 0], bounds[0, 1], 100)
y = np.linspace(bounds[1, 0], bounds[1, 1], 100)
X, Y = np.meshgrid(x, y)
Z = objective(X, Y)
​
fig = plt.figure()
ax = fig.add_subplot(111, projection = "3d")
ax.plot_surface(X, Y, Z, cmap = 'viridis', alpha = 0.5)
ax.scatter(x_min[0], x_min[1], objective(x_min[0], x_min[1]), color = 'red', label = "Минимум")
ax.plot([point[0] for point in trajectory], [point[1] for point in trajectory], scores, color = "blue", label = "Траектория")
ax.set_xlabel("x1")
ax.set_ylabel("x2")
ax.set_zlabel("f(x1, x2)")
ax.legend()
fig.show()
​
Минимум найден:
f([-9.86141076e-05  1.93822431e-09]) = 0.000000
C:\Users\vsoloviev\AppData\Local\Temp\ipykernel_12840\1664080860.py:83: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.
  fig.show()

​
>0 f([ 0.34326042 -0.37804338]) = 0.26074
>1 f([ 0.27453625 -0.30924881]) = 0.17100
>2 f([ 0.19421614 -0.228584  ]) = 0.08997
>3 f([ 0.10889035 -0.14221215]) = 0.03208
>4 f([ 0.02585085 -0.05672143]) = 0.00389
>5 f([-0.04689446  0.02070929]) = 0.00263
>6 f([-0.10197447  0.08315473]) = 0.01731
>7 f([-0.13484511  0.12558593]) = 0.03396
>8 f([-0.1450838   0.14626277]) = 0.04244
>9 f([-0.13578162  0.14679985]) = 0.03999
>10 f([-0.11197782  0.13109868]) = 0.02973
>11 f([-0.07934515  0.10410414]) = 0.01713
>12 f([-0.04341111  0.0709296 ]) = 0.00692
>13 f([-0.00908183  0.03633538]) = 0.00140
>14 f([0.01974401 0.00438002]) = 0.00041
>15 f([ 0.04049811 -0.02185926]) = 0.00212
>16 f([ 0.05210055 -0.04048462]) = 0.00435
>17 f([ 0.05486753 -0.05082857]) = 0.00559
>18 f([ 0.05019851 -0.05332585]) = 0.00536
>19 f([ 0.04015966 -0.049245  ]) = 0.00404
>20 f([ 0.02707544 -0.04036108]) = 0.00236
>21 f([ 0.01318754 -0.02864135]) = 0.00099
>22 f([ 0.00039831 -0.01598289]) = 0.00026
>23 f([-0.00989794 -0.00401516]) = 0.00011
>24 f([-0.01689358  0.00603026]) = 0.00032
>25 f([-0.02035844  0.01338301]) = 0.00059
>26 f([-0.02055673  0.01773377]) = 0.00074
>27 f([-0.01811475  0.01918027]) = 0.00070
>28 f([-0.01386813  0.01813532]) = 0.00052
>29 f([-0.00871393  0.01521597]) = 0.00031
>30 f([-0.0034852   0.01113143]) = 0.00014
>31 f([0.00114122 0.00658319]) = 0.00004
>32 f([0.00469922 0.00218627]) = 0.00003
>33 f([ 0.00695077 -0.00158408]) = 0.00005
>34 f([ 0.0078709  -0.00441915]) = 0.00008
>35 f([ 0.00760856 -0.00617926]) = 0.00010
>36 f([ 0.00643304 -0.00687628]) = 0.00009
>37 f([ 0.00467574 -0.0066421 ]) = 0.00007
>38 f([ 0.00267579 -0.00568955]) = 0.00004
>39 f([ 0.00073552 -0.0042717 ]) = 0.00002
>40 f([-0.00091058 -0.00264476]) = 0.00001
>41 f([-0.0021121  -0.00103794]) = 0.00001
>42 f([-0.00280509  0.00036756]) = 0.00001
>43 f([-0.00300295  0.00144987]) = 0.00001
>44 f([-0.00277935  0.00214865]) = 0.00001
>45 f([-0.00224684  0.00245984]) = 0.00001
>46 f([-0.00153481  0.00242487]) = 0.00001
>47 f([-0.00076969  0.00211689]) = 0.00001
>48 f([-5.94348687e-05  1.62593061e-03]) = 0.00000
>49 f([0.00051648 0.00104521]) = 0.00000
>50 f([0.00091155 0.00045973]) = 0.00000
>51 f([ 1.11153634e-03 -6.19177562e-05]) = 0.00000
>52 f([ 0.0011299  -0.00047219]) = 0.00000
>53 f([ 0.00100056 -0.00074587]) = 0.00000
>54 f([ 0.00076947 -0.0008786 ]) = 0.00000
>55 f([ 0.00048641 -0.00088314]) = 0.00000
>56 f([ 0.00019785 -0.00078456]) = 0.00000
>57 f([-5.83071756e-05 -6.14841190e-04]) = 0.00000
>58 f([-0.00025584 -0.00040783]) = 0.00000
>59 f([-0.00038125 -0.00019495]) = 0.00000
>60 f([-4.32908473e-04 -2.00407550e-06]) = 0.00000
>61 f([-0.00041895  0.00015262]) = 0.00000
>62 f([-0.00035424  0.00025866]) = 0.00000
>63 f([-0.00025719  0.00031352]) = 0.00000
>64 f([-0.00014665  0.00032106]) = 0.00000
>65 f([-3.94373745e-05  2.89846586e-04]) = 0.00000
>66 f([5.13963033e-05 2.31234336e-04]) = 0.00000
>67 f([0.00011751 0.00015749]) = 0.00000
>68 f([1.55370072e-04 8.01992093e-05]) = 0.00000
>69 f([1.65780273e-04 9.03470666e-06]) = 0.00000
>70 f([ 1.52883836e-04 -4.89611239e-05]) = 0.00000
>71 f([ 1.22983466e-04 -8.96809526e-05]) = 0.00000
>72 f([ 8.33018188e-05 -1.11842410e-04]) = 0.00000
>73 f([ 4.08738807e-05 -1.16574315e-04]) = 0.00000
>74 f([ 1.68373938e-06 -1.06805354e-04]) = 0.00000
>75 f([-2.98923813e-05 -8.65654183e-05]) = 0.00000
>76 f([-5.13264122e-05 -6.02980563e-05]) = 0.00000
>77 f([-6.18942357e-05 -3.22616771e-05]) = 0.00000
>78 f([-6.24091916e-05 -6.07139804e-06]) = 0.00000
>79 f([-5.48116071e-05  1.55931856e-05]) = 0.00000
>80 f([-4.16955523e-05  3.11133301e-05]) = 0.00000
>81 f([-2.58459428e-05  3.99081762e-05]) = 0.00000
>82 f([-9.84326746e-06  4.22956299e-05]) = 0.00000
>83 f([4.22682001e-06 3.92763551e-05]) = 0.00000
>84 f([1.49426437e-05 3.22812857e-05]) = 0.00000
>85 f([2.15967855e-05 2.29192866e-05]) = 0.00000
>86 f([2.41446756e-05 1.27543013e-05]) = 0.00000
>87 f([2.30783009e-05 3.13206972e-06]) = 0.00000
>88 f([ 1.92561293e-05 -4.93325908e-06]) = 0.00000
>89 f([ 1.37197899e-05 -1.08113149e-05]) = 0.00000
>90 f([ 7.52369017e-06 -1.42525795e-05]) = 0.00000
>91 f([ 1.59688831e-06 -1.53416387e-05]) = 0.00000
>92 f([-3.35143674e-06 -1.44207725e-05]) = 0.00000
>93 f([-6.87943212e-06 -1.19986873e-05]) = 0.00000
>94 f([-8.81619054e-06 -8.65798781e-06]) = 0.00000
>95 f([-9.22978762e-06 -4.97243227e-06]) = 0.00000
>96 f([-8.37092068e-06 -1.44168343e-06]) = 0.00000
>97 f([-6.60425075e-06  1.55230731e-06]) = 0.00000
>98 f([-4.33872908e-06  3.76648931e-06]) = 0.00000
>99 f([-1.96608057e-06  5.09745817e-06]) = 0.00000
Результат:
f([-1.96608057e-06  5.09745817e-06]) = 0.00000
C:\Users\vsoloviev\AppData\Local\Temp\ipykernel_8380\271599125.py:35: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.
  fig.show()

Задание

Модифицировать класс градиентного спуска для линейной регрессии с использованием алгоритма Adam. Сравнить скорость обучения и качество модели для набора данных videogames.
